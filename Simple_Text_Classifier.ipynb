{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Text Classifier",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TABFR2w3gm1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/"
      ]
    },
    {
      "metadata": {
        "id": "GqramiH5lO1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Scikit-learn: Machine learning in Python\n",
        "\n",
        "Natural Language Toolkit (NLTK): The complete toolkit for all NLP techniques.\n",
        "\n",
        "Pattern – A web mining module for the with tools for NLP and machine learning.\n",
        "\n",
        "TextBlob – Easy to use nl p tools API, built on top of NLTK and Pattern.\n",
        "\n",
        "spaCy – Industrial strength N LP with Python and Cython.\n",
        "\n",
        "Gensim – Topic Modelling for Humans\n",
        "\n",
        "Stanford Core NLP – NLP services and packages by Stanford NLP Group.\n",
        "\n",
        "https://github.com/shivam5992/textstat\n",
        "Textstat"
      ]
    },
    {
      "metadata": {
        "id": "uwZYrFhyaKar",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "bb4fb0a3-2066-457d-cf0d-ba74b8ab7a4a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528428024664,
          "user_tz": 420,
          "elapsed": 6106,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U textblob\n",
        "! python -m textblob.download_corpora"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textblob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/18/7f55c8be6d68ddc4036ffda5382ca51e23a1075987f708b9123712091af1/textblob-0.15.1-py2.py3-none-any.whl (631kB)\n",
            "\u001b[K    100% |████████████████████████████████| 634kB 8.2MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.3)\n",
            "Requirement not upgraded as not directly required: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.15.1\n",
            "[nltk_data] Downloading package brown to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /content/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xP7EmuuaZxFC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b52a392-6152-40b5-d467-11523a74d3ce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528428040470,
          "user_tz": 420,
          "elapsed": 440,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
        "from textblob import TextBlob\n",
        "training_corpus = [\n",
        "                   ('I am exhausted of this work.', 'Class_B'),\n",
        "                   (\"I can't cooperate with this\", 'Class_B'),\n",
        "                   ('He is my badest enemy!', 'Class_B'),\n",
        "                   ('My management is poor.', 'Class_B'),\n",
        "                   ('I love this burger.', 'Class_A'),\n",
        "                   ('This is an brilliant place!', 'Class_A'),\n",
        "                   ('I feel very good about these dates.', 'Class_A'),\n",
        "                   ('This is my best work.', 'Class_A'),\n",
        "                   (\"What an awesome view\", 'Class_A'),\n",
        "                   ('I do not like this dish', 'Class_B')]\n",
        "test_corpus = [(\"I am not feeling well today.\", 'Class_B'), \n",
        "                (\"I feel brilliant!\", 'Class_A'), \n",
        "                ('Gary is a friend of mine.', 'Class_A'), \n",
        "                (\"I can't believe I'm doing this.\", 'Class_B'), \n",
        "                ('The date was good.', 'Class_A'), ('I do not enjoy my job', 'Class_B')]\n",
        "\n",
        "model = NBC(training_corpus) \n",
        "print(model.classify(\"Their codes are amazing.\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class_A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sue97mjVZ6Zj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1ba6b02-5ea4-4fcc-db0a-4bfb2618d0ed",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528428065743,
          "user_tz": 420,
          "elapsed": 335,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.accuracy(test_corpus))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7vKDqx3qaXF6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm \n",
        "\n",
        "# preparing data for SVM model (using the same training_corpus, test_corpus from naive bayes example)\n",
        "train_data = []\n",
        "train_labels = []\n",
        "for row in training_corpus:\n",
        "    train_data.append(row[0])\n",
        "    train_labels.append(row[1])\n",
        "\n",
        "test_data = [] \n",
        "test_labels = [] \n",
        "for row in test_corpus:\n",
        "    test_data.append(row[0]) \n",
        "    test_labels.append(row[1])\n",
        "\n",
        "# Create feature vectors \n",
        "vectorizer = TfidfVectorizer(min_df=4, max_df=0.9)\n",
        "# Train the feature vectors\n",
        "train_vectors = vectorizer.fit_transform(train_data)\n",
        "# Apply model on test data \n",
        "test_vectors = vectorizer.transform(test_data)\n",
        "\n",
        "# Perform classification with SVM, kernel=linear \n",
        "model = svm.SVC(kernel='linear') \n",
        "model.fit(train_vectors, train_labels) \n",
        "prediction = model.predict(test_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYFQQ98KajTc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc069549-c686-43cb-92c7-c3351a36105e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528428216843,
          "user_tz": 420,
          "elapsed": 326,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Class_A', 'Class_A', 'Class_B', 'Class_B', 'Class_A', 'Class_A'],\n",
              "      dtype='<U7')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "zI3ogzC8a7-m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "47b32c8b-b13b-413b-cdf6-fdcf38b48a7e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528428232579,
          "user_tz": 420,
          "elapsed": 340,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print (classification_report(test_labels, prediction))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "    Class_A       0.50      0.67      0.57         3\n",
            "    Class_B       0.50      0.33      0.40         3\n",
            "\n",
            "avg / total       0.50      0.50      0.49         6\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD232MmSa_16",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOE34BMLgu45",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Text Matching / Similarity**\n",
        "\n",
        "Levenshtein Distance – The Levenshtein distance between two strings is defined as the minimum number of edits needed to transform one string into the other, with the allowable edit operations being insertion, deletion, or substitution of a single character. Following is the implementation for efficient memory computations.\n"
      ]
    },
    {
      "metadata": {
        "id": "rzTbTN26c9yh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d913fcb2-bd51-429d-e6d8-b40605581463",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528445547642,
          "user_tz": 420,
          "elapsed": 405,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def levenshtein(s1,s2): \n",
        "    if len(s1) > len(s2):\n",
        "        s1,s2 = s2,s1 \n",
        "    distances = range(len(s1) + 1) \n",
        "    for index2,char2 in enumerate(s2):\n",
        "        newDistances = [index2+1]\n",
        "        for index1,char1 in enumerate(s1):\n",
        "            if char1 == char2:\n",
        "                newDistances.append(distances[index1]) \n",
        "            else:\n",
        "                 newDistances.append(1 + min((distances[index1], distances[index1+1], newDistances[-1]))) \n",
        "        distances = newDistances \n",
        "    return distances[-1]\n",
        "\n",
        "print(levenshtein(\"analyze\",\"analyse\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pS_d5AZdd4wW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Phonetic Matching – A Phonetic matching algorithm takes a keyword as input (person’s name, location name etc) and produces a character string that identifies a set of words that are (roughly) phonetically similar. It is very useful for searching large text corpuses, correcting spelling errors and matching relevant names. Soundex and Metaphone are two main phonetic algorithms used for this purpose. Python’s module Fuzzy is used to compute soundex strings for different words, for example –"
      ]
    },
    {
      "metadata": {
        "id": "G6RMD4uSeaWS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "2e862e75-08f5-4290-9871-9a7bcc1906e4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528445919311,
          "user_tz": 420,
          "elapsed": 9405,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install fuzzy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/b0/210f790e81e3c9f86a740f5384c758ad6c7bc1958332cf64263a9d3cf336/Fuzzy-1.2.2.tar.gz\n",
            "Building wheels for collected packages: fuzzy\n",
            "  Running setup.py bdist_wheel for fuzzy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/79/f7/14/b7e20855729780e85322529469b2d1eadfd940e83d981373cc\n",
            "Successfully built fuzzy\n",
            "Installing collected packages: fuzzy\n",
            "Successfully installed fuzzy-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dE_qBjA2dBny",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "322c1cd8-03c9-4503-8f09-cbd42bea2917",
        "executionInfo": {
          "status": "error",
          "timestamp": 1528445995438,
          "user_tz": 420,
          "elapsed": 439,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import fuzzy \n",
        "soundex = fuzzy.Soundex(4) \n",
        "soundex('fuzzy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-add39fa84cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msoundex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msoundex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fuzzy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32msrc/fuzzy.pyx\u001b[0m in \u001b[0;36mfuzzy.Soundex.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xb1 in position 2: ordinal not in range(128)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Vv8IfH33g1Tc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Flexible String Matching – A complete text matching system includes different algorithms pipelined together to compute variety of text variations. Regular expressions are really helpful for this purposes as well. Another common techniques include – exact string matching, lemmatized matching, and compact matching (takes care of spaces, punctuation’s, slangs etc).\n",
        "\n",
        "D. Cosine Similarity – W hen the text is represented as vector notation, a general cosine similarity can also be applied in order to measure vectorized similarity. Following code converts a text to vectors (using term frequency) and applies cosine similarity to provide closeness among two text."
      ]
    },
    {
      "metadata": {
        "id": "ox7dUFmgeFg5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "febe1025-3b6c-4cbf-903b-976858366f63",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528446999453,
          "user_tz": 420,
          "elapsed": 400,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "def get_cosine(vec1, vec2):\n",
        "    common = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in common])\n",
        "    print (numerator)\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()]) \n",
        "    print(sum1)\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()]) \n",
        "    print(sum2)\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "    print(denominator)\n",
        "    if not denominator:\n",
        "        return 0.0 \n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text): \n",
        "    words = text.split() \n",
        "    return Counter(words)\n",
        "\n",
        "text1 = 'This is an article on analytics vidhya' \n",
        "text2 = 'article on analytics vidhya is about natural language processing'\n",
        "\n",
        "vector1 = text_to_vector(text1) \n",
        "vector2 = text_to_vector(text2) \n",
        "cosine = get_cosine(vector1, vector2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "7\n",
            "9\n",
            "7.937253933193772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v2Dvx1Vmg8oc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23ffa436-f875-4e49-d539-85363e5b2bcf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528446575121,
          "user_tz": 420,
          "elapsed": 531,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cosine"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.629940788348712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "nADMikDug977",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "f97c992d-f343-46da-be99-01d27ece38da",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1528446596240,
          "user_tz": 420,
          "elapsed": 370,
          "user": {
            "displayName": "Aravind Shanmugam",
            "photoUrl": "//lh6.googleusercontent.com/-_XjpUosSEHA/AAAAAAAAAAI/AAAAAAAABA0/uAWQVyYb8sg/s50-c-k-no/photo.jpg",
            "userId": "112465109968057340331"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vector1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'This': 1,\n",
              "         'an': 1,\n",
              "         'analytics': 1,\n",
              "         'article': 1,\n",
              "         'is': 1,\n",
              "         'on': 1,\n",
              "         'vidhya': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "tjx0UVSxhDH9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9flgaJdlAWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other NLP problems / tasks\n",
        "Text Summarization – Given a text article or paragraph, summarize it automatically to produce most important and relevant sentences in order.\n",
        "Machine Translation – Automatically translate text from one human language to another by taking care of grammar, semantics and information about the real world, etc.\n",
        "Natural Language Generation and Understanding – Convert information from computer databases or semantic intents into readable human language is called language generation. Converting chunks of text into more logical structures that are easier for computer programs to manipulate is called language understanding.\n",
        "Optical Character Recognition – Given an image representing printed text, determine the corresponding text.\n",
        "Document to Information – This involves parsing of textual data present in documents (websites, files, pdfs and images) to analyzable and clean format.\n"
      ]
    },
    {
      "metadata": {
        "id": "mnzP3-HWlA73",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}